import json
import os
import logging
import google.generativeai as genai
from tools.notify_tools import send_telegram_msg
from tools.memory_db import save_message, load_history_for_gemini, clear_history
# --- GLOBAL MEMORY (B·ªô nh·ªõ ng·∫Øn h·∫°n - RAM) ---
# C·∫•u tr√∫c: { "chat_id": [historxy_object, ...] }
CHAT_HISTORY = {}
MAX_HISTORY_LEN = 20  # Ch·ªâ nh·ªõ 20 c√¢u g·∫ßn nh·∫•t ƒë·ªÉ ti·∫øt ki·ªám Token

# Configure logging
logger = logging.getLogger(__name__)
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# --- 1. WORKFLOW PH√ÇN T√çCH B√ÄI CH·∫†Y (Gi·ªØ nguy√™n logic c≈©) ---
def analyze_run_with_gemini(activity_id: str, activity_name: str, csv_data: str, config: dict):
    logger.info(f"[COACH AGENT] Analyzing run: {activity_name} (ID: {activity_id})")

    # 1. Setup Context
    system_instruction = config.get("system_instruction", "You are Coach Dyno.")
    user_profile = config.get("user_profile", "")
    full_instruction = f"{system_instruction}\n\n[USER PROFILE DATA]\n{user_profile}"
    
    analysis_requirements = config.get("analysis_requirements", "Analyze HR and Power.")
    output_format = config.get("output_format", "Output in Vietnamese.")
    current_model_name = config.get("model_name", "models/gemini-2.0-flash")

    # 2. Kh·ªüi t·∫°o Model
    try:
        model = genai.GenerativeModel(
            model_name=current_model_name,
            system_instruction=full_instruction
        )
    except Exception as e:
        logger.error(f"Error initializing model {current_model_name}: {e}")
        return None

    # 3. T·∫°o Prompt
    prompt = f"""
    [TASK CONTEXT]
    Activity: {activity_name}
    
    [ANALYSIS REQUIREMENTS]
    {analysis_requirements}
    
    [OUTPUT FORMAT]
    {output_format}
    
    [RAW CSV DATA]
    {csv_data}
    """
    
    if config.get("debug_mode"):
        logger.info(f"[SYSTEM] Analyzing with Model: {current_model_name}")
        # Log prompt ·∫©n data
        log_prompt = prompt.replace(csv_data, f"\n[...CSV HIDDEN {len(csv_data)} bytes...]\n")
        logger.info(f"[PROMPT PREVIEW]\n{log_prompt}")
    try:
        # 4. G·ªçi Gemini ƒë·ªÉ ph√¢n t√≠ch
        response = model.generate_content(prompt)
        analysis_text = response.text

        # üöÄ B∆Ø·ªöC H·ª¢P NH·∫§T: L∆∞u ph√¢n t√≠ch v√†o tr√≠ nh·ªõ h·ªôi tho·∫°i
        # L·∫•y Chat ID t·ª´ bi·∫øn m√¥i tr∆∞·ªùng ho·∫∑c config ƒë·ªÉ ƒë·ªãnh danh ngƒÉn k√©o b·ªô nh·ªõ c·ªßa TinhN
        import os
        chat_id = os.getenv("TELEGRAM_CHAT_ID")
        
        if chat_id and analysis_text:
            # L∆∞u v√†o DB v·ªõi ti·ªÅn t·ªë [STRAVA] ƒë·ªÉ AI sau n√†y d·ªÖ nh·∫≠n di·ªán
            save_message(str(chat_id), "model", f"[STRAVA ANALYSIS] {activity_name}: {analysis_text}")
            logger.info(f"[MEMORY] Analysis merged into Chat History for ID: {chat_id}")

        return analysis_text
        
    except Exception as e:
        logger.error(f"[COACH AGENT] Gemini Error: {e}")
        return None
# --- 2. WORKFLOW CHAT TELEGRAM (N√ÇNG C·∫§P C√ì TR√ç NH·ªö) ---

def handle_telegram_chat(chat_id: str, text: str, config: dict):
    """
    X·ª≠ l√Ω chat v·ªõi b·ªô nh·ªõ vƒ©nh c·ª≠u (SQLite Persistent Memory).
    """
    debug_mode = config.get("debug_mode", False)
    
    # A. X·ª≠ l√Ω l·ªánh ƒë·∫∑c bi·ªát
    if text.strip().lower() in ["/clear", "/reset", "x√≥a nh·ªõ"]:
        clear_history(chat_id) # X√≥a trong DB
        send_telegram_msg(chat_id, "üßπ ƒê√£ x√≥a b·ªô nh·ªõ vƒ©nh c·ª≠u. Ch√∫ng ta b·∫Øt ƒë·∫ßu l·∫°i nh√©!")
        return

    # B. C·∫•u h√¨nh "B·ªô n√£o" (Gi·ªØ nguy√™n logic c≈©)
    current_model_name = config.get("model_name", "models/gemini-2.0-flash")
    system_instruction = config.get("system_instruction", "You are Coach Dyno.")
    user_profile = config.get("user_profile", "")
# --- ƒê·ªåC STATS T·ª™ FILE THU HO·∫†CH ---
    dynamic_stats = ""
    stats_path = "data/athlete_stats.json"
    if os.path.exists(stats_path):
        try:
            with open(stats_path, "r") as f:
                s = json.load(f)
                dynamic_stats = (
                    f"\n[ATHLETE CURRENT STATS]:\n"
                    f"- 4 tu·∫ßn g·∫ßn ƒë√¢y: {s['recent_run_totals']:.1f} km\n"
                    f"- T·ªïng nƒÉm nay: {s['ytd_run_totals']:.1f} km\n"
                )
        except Exception as e:
            logger.error(f"Error reading stats: {e}")
    full_persona = f"""
    {system_instruction}
    
    [USER PROFILE & CONTEXT]
    {user_profile}
    
    [INSTRUCTION]
    - You are chatting directly with the user via Telegram.
    - Keep responses concise, helpful, and friendly.
    """

    try:
        # C. Kh√¥i ph·ª•c l·ªãch s·ª≠ chat t·ª´ SQLITE
        current_history = load_history_for_gemini(chat_id, limit=20)

        model = genai.GenerativeModel(
            model_name=current_model_name,
            system_instruction=full_persona
        )
        
        # D. B·∫ÆT ƒê·∫¶U CHAT V·ªöI L·ªäCH S·ª¨ C≈®
        # L∆∞u √Ω: Gemini t·ª± ƒë·ªông l∆∞u tin nh·∫Øn m·ªõi v√†o chat_session.history
        chat_session = model.start_chat(history=current_history)
        
        # G·ª≠i tin nh·∫Øn m·ªõi
        response = chat_session.send_message(text)
        reply_text = response.text

        # E. L∆ØU C·∫¢ TIN NH·∫ÆN M·ªöI V√Ä PH·∫¢N H·ªíI V√ÄO DB
        save_message(chat_id, "user", text)
        save_message(chat_id, "model", reply_text)

        if debug_mode:
            logger.info(f"[TELEGRAM] Chatting with DB history ({len(current_history)} turns).")

        # F. G·ª≠i k·∫øt qu·∫£
        send_telegram_msg(chat_id, reply_text)
        
    except Exception as e:
        logger.error(f"[TELEGRAM] Chat Error: {e}")
        if "400" in str(e) or "token" in str(e).lower():
            send_telegram_msg(chat_id, "‚ö†Ô∏è B·ªô nh·ªõ h·ªôi tho·∫°i qu√° d√†i. H√£y g√µ /clear ƒë·ªÉ d·ªçn d·∫πp.")
        else:
            send_telegram_msg(chat_id, "‚ö†Ô∏è Coach Dyno ƒëang b·ªã 'chu·ªôt r√∫t'. Th·ª≠ /clear xem sao!")