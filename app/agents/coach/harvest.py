import os
import json
import logging
import asyncio
import io
import pandas as pd
from datetime import datetime, timedelta

from app.agents.coach.strava_client import StravaClient
from app.agents.coach.utils import calculate_trimp, calculate_efficiency_factor, analyze_decoupling
from app.core.config import load_config
from app.core.database import init_db, upsert_user, save_run_activity, save_message, get_db_connection
from app.core.notification import send_telegram_msg
from app.services.rag_memory import rag_db

logger = logging.getLogger("AI_COACH")

def harvest_data():
    """Lu·ªìng Auto-harvest ch·∫°y ng·∫ßm theo l·ªãch Cron"""
    logger.info("[HARVEST] Starting Strava data harvest process...")
    init_db()
    strava_client = StravaClient()
    config = load_config()
    
    chat_id = os.getenv("TELEGRAM_CHAT_ID")
    athlete_id = os.getenv("STRAVA_ATHLETE_ID")

    if not chat_id or not athlete_id: return

    max_hr = int(config.get("max_hr", 185))
    rest_hr = int(config.get("rest_hr", 55))
    upsert_user(user_id=chat_id, name="Primary Runner", max_hr=max_hr, rest_hr=rest_hr)

    athlete_stats = strava_client.get_athlete_stats(athlete_id)
    if athlete_stats:
        os.makedirs("data", exist_ok=True)
        with open("data/athlete_stats.json", "w", encoding="utf-8") as file:
            json.dump(athlete_stats, file, indent=4)

    recent_activities = strava_client.get_recent_activities(limit=10)
    for activity in reversed(recent_activities):
        if activity.get('type') in ['Run', 'TrailRun', 'VirtualRun']:
            dist_km = activity.get('distance', 0) / 1000
            moving_min = activity.get('moving_time', 0) / 60
            avg_hr = activity.get('average_heartrate', 0)
            trimp_data = calculate_trimp(moving_min, avg_hr, max_hr, rest_hr)
            
            activity_data = {
                'activity_id': str(activity.get('id')),
                'name': activity.get('name', 'Unknown Run'),
                'start_date': activity.get('start_date_local'),
                'distance_km': round(dist_km, 2),
                'moving_time_min': round(moving_min, 2),
                'avg_hr': int(avg_hr),
                'max_hr': int(activity.get('max_heartrate', 0)),
                'suffer_score': int(activity.get('suffer_score', 0) or 0),
                'trimp_score': trimp_data.get('trimp', 0.0)
            }
            save_run_activity(user_id=chat_id, activity_data=activity_data)
    logger.info("[HARVEST] Cron Auto-Harvest complete.")

async def execute_manual_sync(chat_id: str, limit: int = 3, days_back: int = None):
    """Lu·ªìng ƒë·ªìng b·ªô l·ªãch s·ª≠ ch·∫°y tay: B·∫£o v·ªá Quota, c·∫•y K√Ω ·ª©c Python tr·ª±c ti·∫øp."""
    logger.info(f"[SYNC] B·∫Øt ƒë·∫ßu ƒë·ªìng b·ªô th·ªß c√¥ng. Limit: {limit}, Days back: {days_back}")
    send_telegram_msg(chat_id, f"‚è≥ ƒêang thu ho·∫°ch d·ªØ li·ªáu Strava ({'30 ng√†y qua' if days_back else f'{limit} b√†i g·∫ßn nh·∫•t'})...")
    
    init_db()
    strava_client = StravaClient()
    config = load_config()
    max_hr = int(config.get("max_hr", 185))
    rest_hr = int(config.get("rest_hr", 55))
    
    recent_activities = strava_client.get_recent_activities(limit=limit)
    target_activities = []
    
    if days_back:
        cutoff_date = datetime.now() - timedelta(days=days_back)
        for act in recent_activities:
            try:
                act_date = datetime.strptime(act['start_date_local'][:10], "%Y-%m-%d")
                if act_date >= cutoff_date: target_activities.append(act)
            except Exception: target_activities.append(act)
    else: target_activities = recent_activities

    if not target_activities:
        send_telegram_msg(chat_id, "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y b√†i ch·∫°y n√†o ph√π h·ª£p.")
        return


    loaded_count = 0
    analyzed_count = 0
    for activity in reversed(target_activities):
        act_id = str(activity.get('id'))
        if activity.get('type') not in ['Run', 'TrailRun', 'VirtualRun']: continue

        # 1. Lu√¥n t√≠nh to√°n v√† c·∫≠p nh·∫≠t SQLite (L·ªánh REPLACE s·∫Ω t·ª± ƒë·ªông ch·ªØa l√†nh/ghi ƒë√® an to√†n)
        dist_km = activity.get('distance', 0) / 1000
        moving_min = activity.get('moving_time', 0) / 60
        avg_hr = activity.get('average_heartrate', 0)
        trimp_data = calculate_trimp(moving_min, avg_hr, max_hr, rest_hr)
        
        activity_data = {
            'activity_id': act_id,
            'name': activity.get('name', 'Unknown Run'),
            'start_date': activity.get('start_date_local'),
            'distance_km': round(dist_km, 2),
            'moving_time_min': round(moving_min, 2),
            'avg_hr': int(avg_hr),
            'max_hr': int(activity.get('max_heartrate', 0)),
            'suffer_score': int(activity.get('suffer_score', 0) or 0),
            'trimp_score': trimp_data.get('trimp', 0.0)
        }
        save_run_activity(user_id=chat_id, activity_data=activity_data)
        loaded_count += 1
        
        # 2. CH·ªêT CH·∫∂N M·ªöI: H·ªèi th·∫≥ng ChromaDB xem k√Ω ·ª©c ƒë√£ c√≥ ch∆∞a?
        existing_memory = rag_db.collection.get(ids=[act_id])
        if existing_memory and existing_memory['ids']:
            logger.info(f"[SYNC] B·ªè qua RAG cho {act_id} v√¨ K√Ω ·ª©c ƒë√£ t·ªìn t·∫°i trong n√£o b·ªô.")
            continue # N·∫øu c√≥ r·ªìi th√¨ b·ªè qua ph·∫ßn t√≠nh Streams b√™n d∆∞·ªõi ƒë·ªÉ ti·∫øt ki·ªám CPU
            
        # 3. N·∫°p K√Ω ·ª©c Python cho nh·ªØng b√†i ch·∫°y b·ªã thi·∫øu (nh∆∞ c√°c b√†i b·ªã l·ªói 429 tr∆∞·ªõc ƒë√¢y)
        logger.info(f"[SYNC] ƒêang v√° l·ªó h·ªïng K√Ω ·ª©c cho b√†i ch·∫°y {act_id}...")
        act_name, csv_data, meta_data = strava_client.get_activity_data(act_id)
        ef_val, decoupling_val, cadence_avg, stride_avg = 0.0, 0.0, 0, 0.0
        pace_str = f"{int(moving_min/dist_km)}:{int(((moving_min/dist_km)%1)*60):02d}" if dist_km > 0 else "0:00"

        if csv_data:
            try:
                df = pd.read_csv(io.StringIO(csv_data))
                if not df.empty:
                    decoupling_val = analyze_decoupling(df)
                    ef_val = calculate_efficiency_factor(df['Velocity_m_s'].mean() * 60, df['HR_bpm'].mean())
                    
                    # [FIX BUG] X·ª≠ l√Ω an to√†n cho Cadence (Tr√°nh l·ªói NaN)
                    c_mean = df['Cadence_spm'].mean() if 'Cadence_spm' in df.columns else 0
                    cadence_avg = int(c_mean) if pd.notna(c_mean) else 0
                    
                    # [FIX BUG] X·ª≠ l√Ω an to√†n cho Stride
                    s_mean = df['Stride_m'].mean() if 'Stride_m' in df.columns else 0.0
                    stride_avg = round(s_mean, 2) if pd.notna(s_mean) else 0.0
            except Exception as e:
                logger.error(f"[SYNC] L·ªói ph√¢n t√≠ch Streams cho {act_id}: {e}")

        memory_content = (
            f"[H·ªí S∆† B√ÄI CH·∫†Y L·ªäCH S·ª¨]\n"
            f"- C∆° b·∫£n: Ng√†y {activity_data['start_date'][:10]}, '{act_name}'. Qu√£ng ƒë∆∞·ªùng {dist_km:.2f}km, th·ªùi gian {moving_min:.1f} ph√∫t.\n"
            f"- T·∫£i tr·ªçng (Load): Tim TB {int(avg_hr)} bpm (Max {int(activity_data['max_hr'])}). TRIMP: {activity_data['trimp_score']} ({trimp_data.get('intensity_level')}).\n"
            f"- Hi·ªáu su·∫•t (Performance): Pace TB {pace_str} min/km. Ch·ªâ s·ªë hi·ªáu qu·∫£ (EF): {ef_val}. ƒê·ªô tr√¥i nh·ªãp tim (Decoupling): {decoupling_val}%.\n"
            f"- K·ªπ thu·∫≠t (Form): Cadence {cadence_avg} spm, S·∫£i ch√¢n {stride_avg} m√©t."
        )

        rag_db.memorize(
            doc_id=act_id,
            content=memory_content,
            domain="coach",
            extra_meta={"user_id": str(chat_id), "type": "historical_run"}
        )
        analyzed_count += 1
        await asyncio.sleep(1)

    send_telegram_msg(chat_id, f"üéâ **Ho√†n t·∫•t ƒê·ªìng b·ªô L·ªãch s·ª≠!**\nƒê√£ b·ªï sung {loaded_count} b√†i ch·∫°y v√†o C∆° s·ªü d·ªØ li·ªáu v√† c·∫•y {analyzed_count} G√≥i K√Ω ·ª©c (EF, Decoupling, TRIMP) v√†o n√£o b·ªô AI. S·ªë li·ªáu ACWR ƒë√£ ƒë∆∞·ª£c c√¢n b·∫±ng.")

if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
    harvest_data()